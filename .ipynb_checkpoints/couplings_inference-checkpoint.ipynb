{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd() + '/src')\n",
    "import utilities as utils\n",
    "\n",
    "from tqdm import tqdm # to compute the time bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LaTeX fonts in the plot\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing High-Order Couplings\n",
    "\n",
    "In this notebook we will present an implementation of the mapping between a Restricted Boltzmann Machine (RBM) and a Potts Model with multi-body interactions.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The RBM is an energy-based model estructured as bipartite neural network. In this model, the visible layer $\\boldsymbol{v} \\!=\\! \\{ v_i \\}_{i=1}^{N_v}$ represents the data, while the hidden layer $\\boldsymbol{h} \\!=\\! \\{ v_i \\}_{i=1}^{N_h}$ accounts the interactions among the visible variables. The probability of a given RBM configuration $\\{ \\boldsymbol{v}, \\boldsymbol{h} \\}$ is determined by the Boltzmann distribution i.,e.\n",
    "$\n",
    "p(\\boldsymbol{v}, \\boldsymbol{h}) \\!\\propto\\! e^{-\\mathcal{H}(\\boldsymbol{v}, \\boldsymbol{h})},\n",
    "$\n",
    "where $\\mathcal{H}$ is the _energy function_ or _Hamiltonian_. Here, we define the hidden nodes as Bernoulli variables, i.e., $h_a \\!\\in\\! \\{0,1\\}$, and visible nodes as categorical variables, or Potts \"spins\", which can take on $q$ states, i.e., $v_i \\!\\in\\! \\{1, \\dots, q \\}$. Hence, the Hamiltonian of such a model is \n",
    "\n",
    "$$\n",
    "\\mathcal{H}(\\boldsymbol{v}, \\boldsymbol{h}) = -\\sum_{i, a, \\mu} W_{ia}^{\\mu} h_a \\delta_{\\mu}^{v_i} - \\sum_{i, \\mu} b_{i}^{\\mu} \\delta_{\\mu}^{v_i} - \\sum_{a} c_a h_a.\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "In the above we used $\\delta$ to denote the Kronecker delta, and $\\boldsymbol{\\Theta} \\!\\equiv\\! \\{ \\boldsymbol{W}, \\boldsymbol{b}, \\boldsymbol{c} \\}$ are the model parameters. Marginalizing Eq. (1) one can obtain the following Hamiltonian:\n",
    "$$\n",
    "\\mathcal{H}(\\boldsymbol{v}) =  - \\sum_{i,\\mu} b_i^\\mu \\delta_\\mu^{v_i} - \\sum_a \\ln \\left(1 + e^{ c_a + \\sum_{i, \\mu} W_{ia}^{\\mu} \\delta_\\mu^{v_i}} \\right).\n",
    "\\tag{2}\n",
    "$$\n",
    "In the Ref. [1], we expanded Eq. (2) as\n",
    "$$\n",
    "\\mathcal{H} (\\boldsymbol{v}) \n",
    "= - \\sum_{i, \\mu} H_i^\\mu \\delta_\\mu^{v_i} - \\sum_{1 \\le i_1 < i_2 \\le N_v} \\sum_{\\mu_1, \\mu_2} \\! \\! J_{ i_1 i_2}^{\\mu_1 \\mu_2} \\delta_{\\mu_1}^{v_{i_1}} \\delta_{\\mu_2}^{v_{i_2}} + \\sum_{1 \\le i_1 < i_2 < i_3 \\le N_v} \\sum_{\\mu_1, \\mu_2, \\mu_3} J_{ i_1 i_2 i_3}^{\\mu_1 \\mu_2 \\mu_3} \\delta_{\\mu_1}^{v_{i_1}} \\delta_{\\mu_2}^{v_{i_2}} \\delta_{\\mu_3}^{v_{i_3}} \\dots,\n",
    "$$\n",
    "with effective couplings (in the zero-sum gauge) given by\n",
    "$$\n",
    "\\hat J_{i_1 \\dots i_n}^{\\mu_1 \\dots \\mu_n}  \n",
    "    = \\sum_{K \\subseteq [n] } (-1)^{n - |K|} \\Bigg[\n",
    "    \\frac{1}{q^{N_v}} \\sum_{\\mu'_1, \\dots, \\mu'_{N_v}} \\sum_a  \n",
    "     \\ln \\left( 1 + e^{c_a +  \\sum_{ k \\in K } W_{i_k a}^{\\mu_k} + \\sum_{ l \\in [N_v] \\setminus K} W_{i_l a}^{\\mu'_l} } \\right) \\Bigg],\n",
    "\\tag{3}\n",
    "$$\n",
    "where introduced $[N] \\equiv \\{1,2, \\dots, N \\}$. We can rewrite Eq. (3) as\n",
    "$$\n",
    "\\hat J_{i_1 \\dots i_n}^{\\mu_1 \\dots \\mu_n}  = \\sum_{K \\subseteq [n]} (-1)^{n-|K|} \\frac{1}{q^n} \\sum_{\\mu'_1, \\dots, \\mu'_n} \\sum_{a} \\mathbb{E}_{x \\sim X_a^{\\left(i_1 \\dots i_n \\right)}} \\left[ \\ln \\left( 1 + e^{c_a + \\sum_{k \\in K} W_{i_k a}^{\\mu_k} + \\sum_{l \\in [n] \\setminus K} W_{i_l a}^{\\mu'_l} + x  } \\right)  \\right],\n",
    "\\tag{4}\n",
    "$$\n",
    "defining $X \\equiv \\sum_{k=n+1}^{N_v} \\! W_{i_k a}^\\ast$, where each $W_{i_k a}^\\ast$ is a random variable uniformly distributed over $\\big\\{W_{i_k a}^\\mu \\!:\\! \\mu \\!\\in\\! [q] \\big\\}$. According to the Central Limit Theorem if $N_v \\gg n$ then $X \\to \\mathcal{N}(0, \\sigma)$, with $\\sigma = \\left[ q^{-1} \\sum_{k=n+1}^{N_v} \\sum_{\\mu=1}^q W_{i_k a}^{\\mu} \\right]^{\\frac{1}{2}}$. Hence, for a sufficiently large $N_v$ and low $n$ we can approximate the expected value in Eq. (4) with the following interal:\n",
    "$$\n",
    "\\frac{1}{\\sqrt{2\\pi} \\sigma } \\int_{-\\infty}^{\\infty} dx \\ e^{-\\frac{x^2}{2 \\sigma^2}} \\ln \\left( 1 + e^{ c_a + \\sum_{ k \\in K } W_{i_k a}^{\\mu_k} + \\sum_{ l \\in [N_v] \\setminus K} W_{i_l a}^{\\mu'_l} + x } \\right),\n",
    "$$\n",
    "which can be computed numerically.\n",
    "\n",
    "\n",
    "In this notebook we will implement a numeric method wich leverages parallel computations in Graphics Proccessing Units to compute effective couplings $\\hat J_{i_1 \\dots i_n}^{\\mu_1 \\dots \\mu_n}$ efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Potts-Bernoulli RBM model\n",
    "\n",
    "Let us use an RBM model trained on Multiple Sequence Alignment data (PF00072) to test our functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = 'PottsBernoulliRBM_PCD-10_mbs=5000_lr=0.01_Nh=1000_centered.h5'\n",
    "\n",
    "# selecting an update to observe\n",
    "update = 51480\n",
    "with h5py.File('models/'+ model_fname, 'r') as f:\n",
    "    n_upd = f['UpdByEpoch'][()]\n",
    "    ep = int(update/n_upd)\n",
    "    W = f['W' + str(ep)][:,:,:].astype(np.float64)  # dim: q x Nv x Nh\n",
    "    b = f['vbias' + str(ep)][:,:].astype(np.float64)  # dim: q x Nv\n",
    "    c = f['hbias' + str(ep)][:].astype(np.float64)  # dim: Nh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBM Fixing Gauge\n",
    "def fix_gauge_RBM(W, b, c, gauge='zero-sum'):\n",
    "    \"\"\"\n",
    "    a Function to fix the gauge in Potts-Bernoulli RBMs\n",
    "\n",
    "    Parameters:\n",
    "    - W: weight matrix (dim: q x Nv x Nh).\n",
    "    - b: visible bias (dim: q x Nv).\n",
    "    - c: hidden bias (dim: Nh).\n",
    "    - gauge: name of the gauge that is going to be fixed. \n",
    "            It could be either 'zero-sum' or 'lattice-gas'.\n",
    "    \"\"\"\n",
    "\n",
    "    if gauge == 'zero-sum':\n",
    "        A = W.mean(axis=0)\n",
    "        bt = b.mean(axis=0)\n",
    "\n",
    "    elif gauge == 'lattice-gas':\n",
    "        # the zero is set in the last color\n",
    "        A = W[-1,:,:]\n",
    "        bt= b[-1,:]\n",
    "    else:\n",
    "        return 'Gauge does not exist'\n",
    "    \n",
    "# it is important to fix the zero-sum gauge in the RBM to get accurate results!\n",
    "fix_gauge_RBM(W, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Functions\n",
    "\n",
    "Now we implement the functions we need to extract the couplings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function to set the device of the RBM parameters\n",
    "def set_device(W, b, c, cuda=True, cuda_device=torch.device('cuda:0')):\n",
    "    \"\"\"\n",
    "    Set the device of RBM paramters.\n",
    "    \n",
    "    Parameters:\n",
    "    - W, b, c: parameters of the RBM.\n",
    "    - cuda: if true it uses cuda, otherwise it uses cpu.\n",
    "    \"\"\"\n",
    "    \n",
    "    if cuda and torch.cuda.is_available():\n",
    "        device = cuda_device\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # loading model paraters\n",
    "    W_torch = torch.from_numpy(W).to(device)\n",
    "    b_torch = torch.from_numpy(b).to(device)\n",
    "    c_torch = torch.from_numpy(c).to(device)\n",
    "    \n",
    "    return W_torch, b_torch, c_torch    \n",
    "\n",
    "# Gaussian function in torch \n",
    "def gaussian(x, loc=0, scale=1):\n",
    "    \"\"\"\n",
    "    It returns the value of a gaussian function.\n",
    "    \n",
    "    Parameters:\n",
    "    - x: variable at which the gaussian function in evaluated.\n",
    "    - loc: location parameter of the gaussian (a.k.a. the mean).\n",
    "    - scale: scale parameter of the gaussian (a.k.a. the standard deviation).\n",
    "    \"\"\"\n",
    "    pi = torch.tensor(math.pi, dtype=x.dtype, device=x.device)\n",
    "    coeff = 1 / (scale * torch.sqrt(2*pi))\n",
    "    exponent = -0.5*(((x - loc)/scale)**2)\n",
    "    return coeff * torch.exp(exponent)\n",
    "\n",
    "# softmax function in torch\n",
    "def softplus(x):\n",
    "    \"\"\"\n",
    "    It computes ln(1 + e^(x)).\n",
    "    \n",
    "    Parameters:\n",
    "    - x: variable at which the function is evaluated.\n",
    "    - b: bias of the function (typically the field plus the weights of sites in j_list).\n",
    "    \"\"\"\n",
    "    return torch.log(1 + torch.exp(x))\n",
    "\n",
    "# estimating the average using a numeric Gaussian integral\n",
    "def est_gaussian_avg(f, bias, loc, scale, n_sigma, n_steps):\n",
    "    \"\"\"\n",
    "    It uses the trapezoid rule of integration to approximate the average of a \n",
    "    function over a Gaussian meassure.\n",
    "    \n",
    "    parameters:\n",
    "    - f: function to average.\n",
    "    - loc: location parameter of the Gaussian (a.k.a. the mean).\n",
    "    - scale: scale parameter of the gaussian (a.k.a. the standard deviation).\n",
    "    - n_sigma: set the wide of the numerical integral in terms of the scale parameter of the gaussian.\n",
    "    - n_steps: number of steps of the numerical integral.\n",
    "    \"\"\"\n",
    "    # numerical integration\n",
    "    beta = n_sigma*scale\n",
    "    alpha = -beta\n",
    "    h = (beta-alpha)/n_steps\n",
    "    I = 0.5*(f(bias + alpha)*gaussian(alpha, loc, scale) \n",
    "             + f(bias + beta)*gaussian(beta, loc, scale))\n",
    "    \n",
    "    for k in range(1, n_steps):\n",
    "        x = alpha + k*h\n",
    "        I += f(bias + x)*gaussian(x, loc, scale)\n",
    "    return torch.sum(h*I, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields\n",
    "\n",
    "From Eq. (4) we derive that formula for the fields:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{J}_{i}^{\\mu} \n",
    "&= \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 \\right)}} \\left [ \\ln \\left( 1 + e^{c_i + W_{i a}^{\\mu} + x } \\right) \\right] - \\frac{1}{q} \\sum_{\\mu'} \\sum_a  \\mathbb{E}_{x \\sim X_a^{\\left(i_1 \\right)}}  \\left [ \\ln \\left( 1 + e^{c_i + W_{ia}^{\\mu'} + x} \\right) \\right].\n",
    "\\tag{5}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields functions\n",
    "def E1_zs(W, c, n_sigma, n_steps):\n",
    "    \"\"\"\n",
    "    It computes the first term of the r.h.s. of Eq. (5).\n",
    "    \n",
    "    Parameters:\n",
    "    - W: weight matrix (dim: q x Nv x Nh)    \n",
    "    - c: hidden fields (dim: Nh)\n",
    "    - n_sigma: set the wide of the numerical integral in terms of the scale parameter of the gaussian.\n",
    "    - n_steps: number of steps of the numerical integral.\n",
    "    \"\"\"\n",
    "    q = W.shape[0]\n",
    "    \n",
    "    # bias of the softmax function\n",
    "    bias = W + c\n",
    "\n",
    "    # scale parameter of the Gaussian measure\n",
    "    sd = torch.sqrt((torch.sum(W**2, dim=(0,1)) - torch.sum(W**2, dim=0))/q)\n",
    "\n",
    "    return est_gaussian_avg(f=softplus, \n",
    "                            bias=bias, \n",
    "                            loc=0.0, scale=sd, \n",
    "                            n_sigma=n_sigma, \n",
    "                            n_steps=n_steps) # dim: q x Nv\n",
    "\n",
    "def H_zs(W, b, c, n_sigma, n_steps):\n",
    "    \"\"\"\n",
    "    It computes a q x Nv effective field matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - W: weight matrix (dim: q x Nv x Nh)  \n",
    "    - b: Visible fields (dim: q x Nv)\n",
    "    - c: hidden fields (dim: Nh)\n",
    "    - n_sigma: set the wide of the numerical integral in terms of the scale parameter of the gaussian.\n",
    "    - n_steps: number of steps of the numerical integral.\n",
    "    \"\"\"\n",
    "    E1_torch = E1_zs(W, c, n_sigma, n_steps)\n",
    "    \n",
    "    return (E1_torch - E1_torch.mean(dim=0) + b) # dim: q x Nvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBM parameters\n",
    "W_torch, b_torch, c_torch = set_device(W, b, c, cuda=True)\n",
    "\n",
    "# parameters of numerical integral \n",
    "n_sigma = 5\n",
    "n_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2 ms ± 36.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "h_torch = H_zs(W_torch, b_torch, c_torch, n_sigma, n_steps) # q x Nv\n",
    "torch.cuda.synchronize()\n",
    "#print(h_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Body Couplings\n",
    "\n",
    "According to Eq. (4) the 2-body effective couplings are given by\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{J}_{i_1 i_2 }^{\\mu_1 \\mu_2} \n",
    "& =  \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 \\right)}}  \\left [ \\ln \\left( 1 + e^{c_a + W_{i a}^{\\mu_1} + W_{i a}^{\\mu_2} + x } \\right) \\right] - \\frac{1}{q} \\sum_{\\mu'_1} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 \\right)}}  \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu'_1} + W_{i_2 a}^{\\mu_2} + x } \\right) \\right] \\\\\n",
    "& - \\frac{1}{q} \\sum_{\\mu'_2} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 \\right)}}  \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu_1} + W_{i_2 a}^{\\mu'_2} + x } \\right) \\right] + \\frac{1}{q^2} \\sum_{\\mu'_1, \\mu'_2} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 \\right)}}  \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu'_1} + W_{i_2 a}^{\\mu'_2} + x } \\right) \\right]. \\tag{6}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-body couplings functions\n",
    "def E2_zs(W, c, i1, i2, n_sigma, n_steps):\n",
    "    \"\"\"\n",
    "    It computes the First term in the r.h.s. of (6).\n",
    "    \n",
    "    Parameters:\n",
    "    - W: weight matrix (dim: q x Nv x Nh)    \n",
    "    - c: hidden fields (dim: Nh)\n",
    "    - i1, i2: visible site index 1, 2\n",
    "    - n_sigma: set the wide of the numerical integral in terms of the scale parameter of the gaussian.\n",
    "    - n_steps: number of steps of the numerical integral.\n",
    "    \"\"\"\n",
    "    W1 = W[:,i1,:]\n",
    "    W2 = W[:,i2,:]\n",
    "    q = W.shape[0]\n",
    "\n",
    "    # bias of the softmax function\n",
    "    bias = W1.unsqueeze(1) + W2.unsqueeze(0) + c\n",
    "\n",
    "    # scale parameter of the Gaussian measure\n",
    "    sd = torch.sqrt((torch.sum(W**2, dim=(0,1)) \n",
    "                     - torch.sum(W1**2, dim=0)\n",
    "                     - torch.sum(W2**2, dim=0)\n",
    "                    )/q)\n",
    "    \n",
    "    return est_gaussian_avg(f=softplus, \n",
    "                            bias=bias, \n",
    "                            loc=0.0, scale=sd, \n",
    "                            n_sigma=n_sigma, \n",
    "                            n_steps=n_steps) # dim: q x q\n",
    "\n",
    "def J2_zs(W, c, i1, i2, n_sigma, n_steps):\n",
    "    \"\"\"\n",
    "    It computes the q x q 2-body coupling matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - W: weight matrix (dim: q x Nv x Nh)    \n",
    "    - c: hidden fields (dim: Nh)\n",
    "    - i1, i2: visible site index 1, 2\n",
    "    - n_sigma: set the wide of the numerical integral in terms of the scale parameter of the gaussian.\n",
    "    - n_steps: number of steps of the numerical integral\n",
    "    \"\"\"\n",
    "    E2_torch = E2_zs(W, c, i1, i2, n_sigma, n_steps)\n",
    "    J2_torch = (E2_torch + E2_torch.mean()\n",
    "                - E2_torch.mean(dim=0).unsqueeze(0) \n",
    "                - E2_torch.mean(dim=1).unsqueeze(1) \n",
    "               )\n",
    "    \n",
    "    return J2_torch # dim: q x q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBM parameters\n",
    "W_torch, b_torch, c_torch = set_device(W, b, c, cuda=True)\n",
    "\n",
    "# parameters of numerical integral \n",
    "n_sigma = 5\n",
    "n_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.42 ms ± 18.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "J2_torch = J2_zs(W_torch, c_torch, 2, 3, n_sigma, n_steps) # q x q\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 6216/6216 [00:27<00:00, 222.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# computating all couplings\n",
    "q, Nv, _ = W.shape\n",
    "J2_matrix = np.zeros((q,q,Nv,Nv))\n",
    "pbar = tqdm(total=int(Nv*(Nv-1)/2), colour='green')\n",
    "for j1 in range(1, Nv):\n",
    "    for j2 in range(j1):\n",
    "        J2_torch = J2_zs(W_torch, c_torch, j1, j2, n_sigma, n_steps)\n",
    "        J2_matrix[:,:, j1, j2] = J2_torch.to('cpu').numpy()\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "J2_matrix = J2_matrix + J2_matrix.transpose(1,0,3,2)\n",
    "# This cell runs in < 30s (in an NVIDIA Geforce RTX 3090 GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-body couplings\n",
    "\n",
    "Hence, the formula for the 3-body couplings is given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{J}_{i_1 i_2 i_3 }^{\\mu_1 \\mu_2 \\mu_3} \n",
    "&=  \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 i_3 \\right)}} \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu_1} + W_{i_2 a}^{\\mu_2} + W_{i_3 a}^{\\mu_3} + x } \\right) \\right] \n",
    "- \\frac{1}{q} \\sum_{\\mu'_1} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 i_3 \\right)}} \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu'_1} + W_{i_2 a}^{\\mu_2} + W_{i_3 a}^{\\mu_3} + x } \\right) \\right] \\\\\n",
    "& - \\frac{1}{q} \\sum_{\\mu'_2} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 i_3 \\right)}} \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu_1} + W_{i_2 a}^{\\mu'_2} + W_{i_3 a}^{\\mu_3} + x } \\right) \\right]\n",
    "- \\frac{1}{q} \\sum_{\\mu'_3} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 i_3 \\right)}} \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu_1} + W_{i_2 a}^{\\mu_2} + W_{i_3 a}^{\\mu'_3} + x } \\right) \\right]\n",
    "\\\\ \n",
    "& + \\frac{1}{q^2} \\sum_{\\mu'_2, \\mu'_3} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 i_3 \\right)}} \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu_1} W_{i_2 a}^{\\mu'_2} + W_{i_3 a}^{\\mu'_3} + x } \\right) \\right] \n",
    "+ \\frac{1}{q^2} \\sum_{\\mu'_1, \\mu'_3} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 i_3 \\right)}} \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu'_1} + W_{i_2 a}^{\\mu_2} + W_{i_3 a}^{\\mu'_3} + x } \\right) \\right] \\\\\n",
    "& + \\frac{1}{q^2} \\sum_{\\mu'_1, \\mu'_2} \\sum_a \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 i_3 \\right)}} \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu'_1} + W_{i_2 a}^{\\mu'_2} + W_{i_3 a}^{\\mu'_3} + x } \\right) \\right]\n",
    "- \\frac{1}{q^3} \\sum_{\\mu'_1, \\mu'_2, \\mu'_3} \\sum_a  \\mathbb{E}_{x \\sim X_a^{\\left(i_1 i_2 i_3 \\right)}} \\left [ \\ln \\left( 1 + e^{c_a + W_{i_1 a}^{\\mu'_1} + W_{i_2 a}^{\\mu'_2} + W_{i j_3}^{\\mu'_3} + x } \\right) \\right]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-body couplings functions\n",
    "def E3_zs(W, c, i1, i2, i3, n_sigma, n_steps):\n",
    "    \"\"\"\n",
    "    Compute the order 3 average in Eq. (3).\n",
    "    \n",
    "    Parameters:\n",
    "    - W: weight matrix (dim: q x Nv x Nh).\n",
    "    - c: hidden fields (dim: Nh).\n",
    "    - i1, i2, i3: visible site index 1, 2, 3.\n",
    "    - n_sigma: set the wide of the numerical integral in terms of the scale parameter of the gaussian.\n",
    "    - n_steps: number of steps of the numerical integral.\n",
    "    \"\"\"\n",
    "    W1 = W[:,i1,:]\n",
    "    W2 = W[:,i2,:]\n",
    "    W3 = W[:,i3,:]\n",
    "    q = W.shape[0]\n",
    "\n",
    "    # bias of the softmax function\n",
    "    bias = (W1.unsqueeze(1).unsqueeze(1) \n",
    "            + W2.unsqueeze(1).unsqueeze(0) \n",
    "            + W3.unsqueeze(0).unsqueeze(0) \n",
    "            + c)\n",
    "\n",
    "    # scale parameter of the Gaussian measure\n",
    "    sd = torch.sqrt((torch.sum(W**2, dim=(0,1)) \n",
    "                      - torch.sum(W1**2, dim=0)\n",
    "                      - torch.sum(W2**2, dim=0)\n",
    "                      - torch.sum(W3**2, dim=0)\n",
    "                     )/q)\n",
    "\n",
    "    return est_gaussian_avg(f=softplus, \n",
    "                            bias=bias, \n",
    "                            loc=0.0, scale=sd, \n",
    "                            n_sigma=n_sigma, \n",
    "                            n_steps=n_steps) # dim: q x q x q\n",
    "\n",
    "def J3_zs(W, c, i1, i2, i3, n_sigma, n_steps):\n",
    "    \"\"\"\n",
    "    Compute the q x q x q 3-body coupling tensor.\n",
    "    \n",
    "    Parameters:\n",
    "    - W: weight matrix (dim: q x Nv x Nh).\n",
    "    - c: hidden fields (dim: Nh).\n",
    "    - i1, i2, i3: visible site index 1, 2, 3.\n",
    "    - n_sigma: set the wide of the numerical integral in terms of the scale parameter of the gaussian.\n",
    "    - n_steps: number of steps of the numerical integral.\n",
    "    \"\"\"\n",
    "    E3_torch = E3_zs(W, c, i1, i2, i3, n_sigma, n_steps)\n",
    "    J3_torch = (E3_torch - E3_torch.mean()\n",
    "                - E3_torch.mean(dim=0).unsqueeze(0) \n",
    "                - E3_torch.mean(dim=1).unsqueeze(1) \n",
    "                - E3_torch.mean(dim=2).unsqueeze(2) \n",
    "                + E3_torch.mean(dim=(1,2)).unsqueeze(1).unsqueeze(2)\n",
    "                + E3_torch.mean(dim=(0,1)).unsqueeze(0).unsqueeze(1)\n",
    "                + E3_torch.mean(dim=(0,2)).unsqueeze(0).unsqueeze(2)\n",
    "               )\n",
    "    \n",
    "    return J3_torch # dim: q x q x q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBM parameters\n",
    "W_torch, b_torch, c_torch = set_device(W, b, c, cuda=True)\n",
    "\n",
    "# parameters of numerical integral \n",
    "n_sigma = 5\n",
    "n_steps = 20\n",
    "i1, i2, i3 = 109, 10, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.6 ms ± 101 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Computing 2-body coupling for a triplet (j1, j2, j3)\n",
    "J3_torch = J3_zs(W_torch, c_torch, i1, i2, i3, n_sigma, n_steps)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    " [1] Decelle, A., Navas Gómez, A. J., & Seoane, B. (2025). _Inferring High-Order Couplings with Neural Networks_. [arXiv preprint arXiv:2501.06108](https://doi.org/10.48550/arXiv.2501.06108)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
